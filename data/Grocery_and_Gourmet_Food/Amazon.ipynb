{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9afc608b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT: E:\\ReChorus-master\n",
      "DATA_DIR: E:\\ReChorus-master\\data\\Grocery_and_Gourmet_Food\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 0: 常量、依赖与随机种子 ====\n",
    "import os, json, gzip, urllib.request, random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "\n",
    "# 路径与数据集名\n",
    "ROOT = Path(r\"E:\\ReChorus-master\")\n",
    "DATASET = \"Grocery_and_Gourmet_Food\"\n",
    "DATA_DIR = ROOT / \"data\" / DATASET\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 统一随机种子（下载不受影响，采样/划分会用到）\n",
    "RANDOM_SEED = 2025\n",
    "NEG_ITEMS   = 100   # TopK 每条样本的负采样个数；dev/test 的负采样同用\n",
    "random.seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "try:\n",
    "    import torch\n",
    "    torch.manual_seed(RANDOM_SEED)\n",
    "    torch.cuda.manual_seed_all(RANDOM_SEED)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print(\"ROOT:\", ROOT)\n",
    "print(\"DATA_DIR:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db607b7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[exist] reviews_Grocery_and_Gourmet_Food_5.json.gz\n",
      "[exist] meta_Grocery_and_Gourmet_Food.json.gz\n",
      "Done. Files under: E:\\ReChorus-master\\data\\Grocery_and_Gourmet_Food\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 1: 下载原始数据（若已存在则跳过） ====\n",
    "DATA_FILE = f\"reviews_{DATASET}_5.json.gz\"\n",
    "META_FILE = f\"meta_{DATASET}.json.gz\"\n",
    "\n",
    "sources = [\n",
    "    (DATA_FILE, f\"https://snap.stanford.edu/data/amazon/productGraph/categoryFiles/{DATA_FILE}\"),\n",
    "    (META_FILE, f\"https://snap.stanford.edu/data/amazon/productGraph/categoryFiles/{META_FILE}\"),\n",
    "]\n",
    "\n",
    "for fname, url in sources:\n",
    "    out = DATA_DIR / fname\n",
    "    if out.exists():\n",
    "        print(\"[exist]\", out.name)\n",
    "    else:\n",
    "        print(\"[download]\", url, \"->\", out)\n",
    "        urllib.request.urlretrieve(url, out)\n",
    "\n",
    "print(\"Done. Files under:\", DATA_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f1b7b9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviews: (151254, 9) columns: ['reviewerID', 'asin', 'reviewerName', 'helpful', 'reviewText', 'overall', 'summary', 'unixReviewTime']\n",
      "meta   : (171760, 9) columns: ['asin', 'description', 'title', 'imUrl', 'related', 'salesRank', 'categories', 'price']\n",
      "#Users: 14681 #Items: 8713 #Interactions: 151254\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 2: 解析 gz → DataFrame ====\n",
    "def parse_gz_json(path: Path):\n",
    "    with gzip.open(path, 'rb') as g:\n",
    "        for line in g:\n",
    "            yield eval(line)  # Amazon 官方示例使用的简便写法\n",
    "\n",
    "def load_df(path: Path) -> pd.DataFrame:\n",
    "    data = {}\n",
    "    for i, obj in enumerate(parse_gz_json(path)):\n",
    "        data[i] = obj\n",
    "    return pd.DataFrame.from_dict(data, orient=\"index\")\n",
    "\n",
    "review_fp = DATA_DIR / f\"reviews_{DATASET}_5.json.gz\"\n",
    "meta_fp   = DATA_DIR / f\"meta_{DATASET}.json.gz\"\n",
    "\n",
    "reviews = load_df(review_fp)\n",
    "meta    = load_df(meta_fp)\n",
    "\n",
    "print(\"reviews:\", reviews.shape, \"columns:\", list(reviews.columns)[:8])\n",
    "print(\"meta   :\", meta.shape,    \"columns:\", list(meta.columns)[:8])\n",
    "\n",
    "# 只保留交互中出现过的物品\n",
    "meta_use = meta[meta['asin'].isin(reviews['asin'])].reset_index(drop=True)\n",
    "all_asins = set(meta_use['asin'])\n",
    "\n",
    "def related_filter(related_dict):\n",
    "    out = {}\n",
    "    if isinstance(related_dict, dict):\n",
    "        for k, lst in related_dict.items():\n",
    "            out[k] = list(all_asins & set(lst))\n",
    "    return out\n",
    "\n",
    "if 'related' in meta_use.columns:\n",
    "    meta_use['related'] = meta_use['related'].apply(related_filter)\n",
    "else:\n",
    "    meta_use['related'] = [{} for _ in range(len(meta_use))]\n",
    "\n",
    "print(\"#Users:\", reviews['reviewerID'].nunique(),\n",
    "      \"#Items:\", reviews['asin'].nunique(),\n",
    "      \"#Interactions:\", len(reviews))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9e910c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[base csv] saved -> E:\\ReChorus-master\\data\\Grocery_and_Gourmet_Food\\train.csv E:\\ReChorus-master\\data\\Grocery_and_Gourmet_Food\\dev.csv E:\\ReChorus-master\\data\\Grocery_and_Gourmet_Food\\test.csv\n",
      "[item meta] saved -> E:\\ReChorus-master\\data\\Grocery_and_Gourmet_Food\\item_meta.csv\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 3: 构造交互表（逗号 CSV：user_id,item_id,time）+ item_meta ====\n",
    "# 1) 重命名 → 去重 → 排序\n",
    "inter = reviews.rename(columns={'reviewerID':'user_id','asin':'item_id','unixReviewTime':'time'})\n",
    "inter = inter[['user_id','item_id','time']].drop_duplicates()\n",
    "inter = inter.sort_values(by=['time','user_id'], kind='mergesort').reset_index(drop=True)\n",
    "\n",
    "# 2) 重新编号（从 1 开始）\n",
    "uid_list = sorted(inter['user_id'].unique())\n",
    "iid_list = sorted(inter['item_id'].unique())\n",
    "user2id = dict(zip(uid_list, range(1, len(uid_list)+1)))\n",
    "item2id = dict(zip(iid_list, range(1, len(iid_list)+1)))\n",
    "\n",
    "inter['user_id'] = inter['user_id'].map(user2id).astype(int)\n",
    "inter['item_id'] = inter['item_id'].map(item2id).astype(int)\n",
    "inter['time']    = inter['time'].astype(int)\n",
    "\n",
    "# 3) leave-one-out：每个用户最后两条做 test/dev，其余做 train（再把每个用户最早一条加入 train，保持稳定）\n",
    "clicked_item_set = {u: set(g['item_id'].tolist()) for u, g in inter.groupby('user_id')}\n",
    "\n",
    "def make_dev_test(df: pd.DataFrame):\n",
    "    res = []\n",
    "    n_items = df['item_id'].nunique()\n",
    "    work = df.copy()\n",
    "    for _ in range(2):  # test/dev 各取最后一条\n",
    "        last = work.groupby('user_id').tail(1).copy()\n",
    "        work = work.drop(last.index)\n",
    "        # （可选）保留一个 neg_items 列（后面会重采，这里不强依赖）\n",
    "        res.append(last)\n",
    "    return (res[0], res[1], work)  # test, dev, remain\n",
    "\n",
    "# 每个用户的第一条保底放回 train\n",
    "head1 = inter.groupby('user_id').head(1)\n",
    "rest  = inter.drop(head1.index)\n",
    "test_df, dev_df, remain_df = make_dev_test(rest)\n",
    "train_df = pd.concat([head1, remain_df]).sort_index()\n",
    "\n",
    "# 4) 保存“标准化的逗号 CSV”（框架中间产物；最终训练会用下面生成的子目录）\n",
    "train_csv = DATA_DIR / \"train.csv\"\n",
    "dev_csv   = DATA_DIR / \"dev.csv\"\n",
    "test_csv  = DATA_DIR / \"test.csv\"\n",
    "\n",
    "train_df[['user_id','item_id','time']].to_csv(train_csv, index=False)  # 逗号\n",
    "dev_df[['user_id','item_id','time']].to_csv(dev_csv, index=False)\n",
    "test_df[['user_id','item_id','time']].to_csv(test_csv, index=False)\n",
    "\n",
    "print(\"[base csv] saved ->\", train_csv, dev_csv, test_csv)\n",
    "\n",
    "# 5) 物品侧信息（逗号 CSV）\n",
    "#   二级品类\n",
    "l2 = []\n",
    "cats = meta_use.get('categories', [])\n",
    "for row in cats:\n",
    "    if isinstance(row, list) and len(row)>0 and len(row[0])>2:\n",
    "        l2.append(row[0][2])\n",
    "    else:\n",
    "        l2.append(np.nan)\n",
    "meta_use['l2_category'] = l2\n",
    "l2_vals = sorted(meta_use['l2_category'].dropna().unique())\n",
    "l2_map  = dict(zip(l2_vals, range(1, len(l2_vals)+1)))\n",
    "meta_use['l2_category'] = meta_use['l2_category'].apply(lambda x: l2_map[x] if x==x else 0)\n",
    "\n",
    "#   映射 related 到新 item_id 空间\n",
    "item_meta_rows = []\n",
    "for _, r in meta_use.iterrows():\n",
    "    asin = r['asin']\n",
    "    if asin not in item2id:\n",
    "        continue\n",
    "    info = r['related'] if isinstance(r['related'], dict) else {}\n",
    "    item_meta_rows.append({\n",
    "        'item_id'     : item2id[asin],\n",
    "        'i_category'  : r['l2_category'],\n",
    "        'r_complement': [item2id[x] for x in info.get('also_bought', []) if x in item2id],\n",
    "        'r_substitute': [item2id[x] for x in info.get('also_viewed', []) if x in item2id],\n",
    "    })\n",
    "item_meta = pd.DataFrame(item_meta_rows, columns=['item_id','i_category','r_complement','r_substitute'])\n",
    "item_meta_csv = DATA_DIR / \"item_meta.csv\"\n",
    "item_meta.to_csv(item_meta_csv, index=False)\n",
    "print(\"[item meta] saved ->\", item_meta_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51f34cb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GGFTOPK] train.csv -> (121892, 4) ['user_id', 'item_id', 'time', 'neg_items']\n",
      "[GGFTOPK] dev.csv -> (14681, 4) ['user_id', 'item_id', 'time', 'neg_items']\n",
      "[GGFTOPK] test.csv -> (14681, 4) ['user_id', 'item_id', 'time', 'neg_items']\n",
      "[GGFCTR ] train.csv -> (243784, 4) ['user_id', 'item_id', 'time', 'label']\n",
      "[GGFCTR ] dev.csv -> (29362, 4) ['user_id', 'item_id', 'time', 'label']\n",
      "[GGFCTR ] test.csv -> (29362, 4) ['user_id', 'item_id', 'time', 'label']\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 4: 生成 GGFTOPK 与 GGFCTR（TSV） ====\n",
    "TOPK_DIR = DATA_DIR / \"GGFTOPK\"\n",
    "CTR_DIR  = DATA_DIR / \"GGFCTR\"\n",
    "TOPK_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CTR_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# 读取标准化 base csv（逗号）\n",
    "base = {\n",
    "    \"train\": pd.read_csv(DATA_DIR / \"train.csv\"),\n",
    "    \"dev\"  : pd.read_csv(DATA_DIR / \"dev.csv\"),\n",
    "    \"test\" : pd.read_csv(DATA_DIR / \"test.csv\"),\n",
    "}\n",
    "for k in base:\n",
    "    base[k] = base[k][[\"user_id\",\"item_id\",\"time\"]].astype({\"user_id\":int,\"item_id\":int,\"time\":int})\n",
    "\n",
    "# 全局候选 & 用户历史（用于负采样）\n",
    "all_df    = pd.concat(base.values(), ignore_index=True)\n",
    "all_items = np.asarray(sorted(all_df[\"item_id\"].unique()), dtype=int)\n",
    "user_hist = defaultdict(set)\n",
    "for u, i in zip(all_df[\"user_id\"].values, all_df[\"item_id\"].values):\n",
    "    user_hist[int(u)].add(int(i))\n",
    "\n",
    "rng = np.random.default_rng(RANDOM_SEED)\n",
    "\n",
    "def candidate_pool(u: int) -> np.ndarray:\n",
    "    seen = user_hist[u]\n",
    "    if not seen:\n",
    "        return all_items\n",
    "    cand = np.setdiff1d(all_items, np.fromiter(seen, dtype=int), assume_unique=False)\n",
    "    return cand if cand.size>0 else all_items\n",
    "\n",
    "# ====== A) GGFTOPK：为 train/dev/test 每条样本生成 NEG_ITEMS 个未交互负例（列名 neg_items） ======\n",
    "for split in [\"train\",\"dev\",\"test\"]:\n",
    "    df = base[split].copy()\n",
    "    neg_lists = []\n",
    "    for u in df[\"user_id\"].values:\n",
    "        cand = candidate_pool(int(u))\n",
    "        neg_lists.append(list(rng.choice(cand, size=NEG_ITEMS, replace=True).astype(int)))\n",
    "    df[\"neg_items\"] = neg_lists\n",
    "    # **关键**：ReChorus 这套脚本在 Amazon 上常用 TSV\n",
    "    df.to_csv(TOPK_DIR / f\"{split}.csv\", index=False, sep=\"\\t\")\n",
    "    print(f\"[GGFTOPK] {split}.csv ->\", df.shape, list(df.columns))\n",
    "\n",
    "# ====== B) GGFCTR：1:1 负采样（含 label），保留 time；同样用 TSV ======\n",
    "def build_ctr(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    pos = df[[\"user_id\",\"item_id\",\"time\"]].copy().astype(int)\n",
    "    pos[\"label\"] = 1\n",
    "    neg_rows = []\n",
    "    for u, t in zip(pos[\"user_id\"].values, pos[\"time\"].values):\n",
    "        cand = candidate_pool(int(u))\n",
    "        j = int(rng.choice(cand))\n",
    "        neg_rows.append((int(u), j, int(t), 0))\n",
    "    neg = pd.DataFrame(neg_rows, columns=[\"user_id\",\"item_id\",\"time\",\"label\"])\n",
    "    return pd.concat([pos, neg], ignore_index=True)\n",
    "\n",
    "for split in [\"train\",\"dev\",\"test\"]:\n",
    "    out = build_ctr(base[split])\n",
    "    out.to_csv(CTR_DIR / f\"{split}.csv\", index=False, sep=\"\\t\")\n",
    "    print(f\"[GGFCTR ] {split}.csv ->\", out.shape, list(out.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15196957",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== GGFTOPK ==\n",
      "train.csv (121892, 4) ['user_id', 'item_id', 'time', 'neg_items']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>neg_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2177</td>\n",
       "      <td>3</td>\n",
       "      <td>965779200</td>\n",
       "      <td>[3899, 8665, 8649, 3329, 8310, 7208, 5572, 729...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4161</td>\n",
       "      <td>18</td>\n",
       "      <td>1068249600</td>\n",
       "      <td>[3844, 1961, 4150, 7837, 2152, 2808, 5721, 286...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time  \\\n",
       "0     2177        3   965779200   \n",
       "1     4161       18  1068249600   \n",
       "\n",
       "                                           neg_items  \n",
       "0  [3899, 8665, 8649, 3329, 8310, 7208, 5572, 729...  \n",
       "1  [3844, 1961, 4150, 7837, 2152, 2808, 5721, 286...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.csv (14681, 4) ['user_id', 'item_id', 'time', 'neg_items']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>neg_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6185</td>\n",
       "      <td>691</td>\n",
       "      <td>1149206400</td>\n",
       "      <td>[8418, 8475, 8661, 7637, 7586, 2717, 930, 7893...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10679</td>\n",
       "      <td>912</td>\n",
       "      <td>1150675200</td>\n",
       "      <td>[1635, 2017, 911, 7651, 2306, 5111, 3946, 1736...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time  \\\n",
       "0     6185      691  1149206400   \n",
       "1    10679      912  1150675200   \n",
       "\n",
       "                                           neg_items  \n",
       "0  [8418, 8475, 8661, 7637, 7586, 2717, 930, 7893...  \n",
       "1  [1635, 2017, 911, 7651, 2306, 5111, 3946, 1736...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv (14681, 4) ['user_id', 'item_id', 'time', 'neg_items']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>neg_items</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6185</td>\n",
       "      <td>762</td>\n",
       "      <td>1149206400</td>\n",
       "      <td>[6260, 4830, 1273, 3653, 6061, 5957, 3380, 766...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3299</td>\n",
       "      <td>1096</td>\n",
       "      <td>1154044800</td>\n",
       "      <td>[2252, 2453, 5228, 452, 2581, 4561, 422, 6917,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time  \\\n",
       "0     6185      762  1149206400   \n",
       "1     3299     1096  1154044800   \n",
       "\n",
       "                                           neg_items  \n",
       "0  [6260, 4830, 1273, 3653, 6061, 5957, 3380, 766...  \n",
       "1  [2252, 2453, 5228, 452, 2581, 4561, 422, 6917,...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== GGFCTR ==\n",
      "train.csv (243784, 4) ['user_id', 'item_id', 'time', 'label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2177</td>\n",
       "      <td>3</td>\n",
       "      <td>965779200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4161</td>\n",
       "      <td>18</td>\n",
       "      <td>1068249600</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time  label\n",
       "0     2177        3   965779200      1\n",
       "1     4161       18  1068249600      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev.csv (29362, 4) ['user_id', 'item_id', 'time', 'label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6185</td>\n",
       "      <td>691</td>\n",
       "      <td>1149206400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10679</td>\n",
       "      <td>912</td>\n",
       "      <td>1150675200</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time  label\n",
       "0     6185      691  1149206400      1\n",
       "1    10679      912  1150675200      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test.csv (29362, 4) ['user_id', 'item_id', 'time', 'label']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>time</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6185</td>\n",
       "      <td>762</td>\n",
       "      <td>1149206400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3299</td>\n",
       "      <td>1096</td>\n",
       "      <td>1154044800</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id        time  label\n",
       "0     6185      762  1149206400      1\n",
       "1     3299     1096  1154044800      1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ 准备就绪：接下来直接用 --dataset \"Grocery_and_Gourmet_Food/GGFTOPK\" 或 \"Grocery_and_Gourmet_Food/GGFCTR\" 训练即可。\n"
     ]
    }
   ],
   "source": [
    "# ==== Cell 5: 快速自检 ====\n",
    "def peek(path: Path, n=2):\n",
    "    df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "    print(path.name, df.shape, list(df.columns))\n",
    "    display(df.head(n))\n",
    "\n",
    "print(\"== GGFTOPK ==\")\n",
    "for sp in [\"train\",\"dev\",\"test\"]:\n",
    "    peek((DATA_DIR / \"GGFTOPK\" / f\"{sp}.csv\"))\n",
    "\n",
    "print(\"== GGFCTR ==\")\n",
    "for sp in [\"train\",\"dev\",\"test\"]:\n",
    "    peek((DATA_DIR / \"GGFCTR\" / f\"{sp}.csv\"))\n",
    "\n",
    "print(\"\\n✅ 准备就绪：接下来直接用 --dataset \\\"Grocery_and_Gourmet_Food/GGFTOPK\\\" 或 \\\"Grocery_and_Gourmet_Food/GGFCTR\\\" 训练即可。\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chorus",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
